{
  "modules": [
    {
      "id": "bp-dpa-02-etl-fundamentals",
      "title": "ETL-Prozesse und Datenintegration",
      "description": "Extract, Transform, Load - Grundlagen der Datenintegration und ETL-Pipeline-Design",
      "category": "BP-DPA-01",
      "subcategory": "Daten erfassen, aufbereiten und auswerten",
      "difficulty": "intermediate",
      "examRelevance": "high",
      "newIn2025": false,
      "removedIn2025": false,
      "important": true,
      "estimatedTime": 55,
      "prerequisites": [],
      "tags": [
        "ETL",
        "Datenintegration",
        "Extract",
        "Transform",
        "Load",
        "Data Pipeline"
      ],
      "content": "# ETL-Prozesse und Datenintegration\n\n## Einführung\n\nETL (Extract, Transform, Load) ist ein fundamentaler Prozess in der Datenverarbeitung, der es ermöglicht, Daten aus verschiedenen Quellen zu extrahieren, zu transformieren und in Zielsysteme zu laden. Für Fachinformatiker der Fachrichtung Daten- und Prozessanalyse ist das Verständnis von ETL-Prozessen essentiell für effektive Datenintegration.\n\n## ETL-Grundlagen\n\n### Definition\n\nETL ist ein dreistufiger Prozess zur Datenintegration: Extract (Extrahieren), Transform (Transformieren), Load (Laden).\n\n## ... (see backup for full content)",
      "codeExamples": [],
      "relatedQuizzes": ["bp-dpa-02-etl-quiz"],
      "resources": [
        {
          "title": "Apache Airflow Documentation",
          "url": "https://airflow.apache.org/docs/",
          "type": "documentation"
        },
        {
          "title": "Talend Open Studio",
          "url": "https://www.talend.com/products/talend-open-studio/",
          "type": "tool"
        }
      ],
      "learningObjectives": [
        "ETL-Prozess verstehen und implementieren",
        "Extraktionsstrategien auswählen und anwenden",
        "Datentransformation und -bereinigung durchführen",
        "Ladestrategien und SCD-Typen implementieren",
        "Datenqualität in ETL-Pipelines sicherstellen"
      ],
      "keyTakeaways": [
        "ETL ist fundamental für Datenintegration und -qualität",
        "Inkrementelle Extraktion ist effizienter bei großen Datenmengen",
        "Datentransformation erfordert umfassende Validierung",
        "SCD-Typen ermöglichen Historisierung von Änderungen"
      ],
      "lastUpdated": "2025-01-20T00:00:00Z",
      "version": "1.0",
      "tracks": ["DPA"]
    }
  ]
}
